{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask at CHTC Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently playing with what it takes to spawn Dask workers on the CHTC pool. This notebook (and repository) encapsulate a prototype/demo of doing just that, running from a CHTC submit node and spawning Dask workers in the CHTC pool. We'll do some basic Dask work with CPU workers, then get a few GPU workers and prove we can talk to their GPUs.\n",
    "\n",
    "Warning! Things will probably go wrong at some point.\n",
    "\n",
    "This is not ready for production! There's a lot of hacks, and there's a lot of out-of-band system administration going on behind the scenes to make it work for this demo. Do not try this at home... but please get in contact with me (Josh Karpel) or Brian Bockelman if you're interested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Cluster and Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is a Python library for flexible parallel computing. It is *flexible* in two ways:\n",
    "- It supports both low-level and high-level parallelism, and anywhere in-between. In this demo, we'll see examples along that entire spectrum.\n",
    "- User code generally does not need to change much when the size/shape of the Dask cluster you are connected to changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first order of business is to create a \"cluster\" to manage worker jobs on the pool. We feed the cluster to a \"client\", which is an object that we can use to ask Dask to do work. Many operations on Dask-provided objects, like data arrays, implicitly use the client to do work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_chtc import CHTCCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "WORKER_IMAGE = \"maventree/dask-worker:demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = CHTCCluster(worker_image = WORKER_IMAGE)\n",
    "cluster.scale(10)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Level Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is capable of parallelizing low-level operations on arrays. All we need to tell Dask is how big the smallest \"chunk\" of the array it should operate on is. Dask will perform operations on individual chunks out on the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.ones((15, 15), chunks=5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + x.T\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that whoever wrote Dask's transpose algorithm has realized that the chunks along the diagonal don't need to know about any other chunks, while the off-diagonal chunks do. Dask has figured out an efficient workflow automatically, without you needing to be clever yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.compute()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask implicitly does this kind of work by overriding normal operations on arrays, as well as implementing most of the `numpy` interface. It has equivalents of pandas dataframes as well. Most of the time, you can write \"natural\" scientific Python code, and Dask will handle the parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.random.random((10000, 10000), chunks=1000)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ((x ** 2) + 1).sum() ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.compute()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scales up to big operations as well. For example, Dask provides an implemention of SVD, built on top of its other functionality. This combines many operations and has a much more complex task graph, but you don't need to know any of that - just call `svd`! If you need to do other operations on the inputs or results, Dask will join them all together into one big task graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.ones((10_000, 1_000), chunks=(1_000, 1_000))\n",
    "u, s, v = da.linalg.svd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = dask.compute(u, s, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning and High-Level Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask-ML provides Dask-based implemenations of various tools commonly used in ML, like clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.datasets\n",
    "import dask_ml.cluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dask_ml.datasets.make_blobs(\n",
    "    n_samples=10_000_000,\n",
    "    chunks=1_000_000,\n",
    "    centers=5,\n",
    "    center_box=(-10, 10),\n",
    "    random_state=11\n",
    ")\n",
    "X = X.persist()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSITY = 1000\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[::DENSITY, 0], X[::DENSITY, 1], \n",
    "           marker='.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = dask_ml.cluster.KMeans(n_clusters=5, init_max_iter=2, oversampling_factor=10)\n",
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[::DENSITY, 0], X[::DENSITY, 1], \n",
    "           marker='.', \n",
    "           c=km.labels_[::DENSITY],\n",
    "           cmap='viridis', alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has equivalents of scikit-learn's hyperparameter optimization tools... as well as some fancier ones, like Scott Sievert's hyperband implementation! (https://examples.dask.org/machine-learning/hyperparam-opt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import make_hyperparameter_optimization_problem, make_train_test\n",
    "\n",
    "X, y = make_hyperparameter_optimization_problem()\n",
    "X_train, X_test, y_train, y_test = make_train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "\n",
    "params = {\n",
    "    \"hidden_layer_sizes\": [\n",
    "        (24,),\n",
    "        (12, 12),\n",
    "        (6, 6, 6, 6),\n",
    "        (4, 4, 4, 4, 4, 4),\n",
    "        (12, 6, 3, 3),\n",
    "    ],\n",
    "    \"activation\": [\"relu\", \"logistic\", \"tanh\"],\n",
    "    \"alpha\": np.logspace(-6, -3, num=1000),\n",
    "    \"batch_size\": [16, 32, 64, 128, 256, 512],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 10 * len(X_train)\n",
    "n_params = 20\n",
    "\n",
    "max_iter = n_params  # number of times partial_fit will be called\n",
    "chunks = n_examples // n_params  # number of examples each call sees\n",
    "\n",
    "X_train2 = da.from_array(X_train, chunks=chunks)\n",
    "y_train2 = da.from_array(y_train, chunks=chunks)\n",
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "\n",
    "search = HyperbandSearchCV(\n",
    "    model,\n",
    "    params,\n",
    "    max_iter=max_iter,\n",
    "    patience=True,\n",
    ")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train2, y_train2, classes=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dask-ML does not provide its own model description language. Instead, it can work with anything obeying the scikit-learn API, namely scikit-learn itself and PyTorch with the Skorch wrapper layer, which we'll see in the final example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowe we'll shut down the \"CPU\" client we made earlier, and start up a new \"GPU\" client. The only difference is that the underlying HTCondor jobs now request GPUs.\n",
    "\n",
    "You may need to poke the Dask Dashboard to get it to register the new client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_chtc import CHTCCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "WORKER_IMAGE = \"maventree/dask-worker:demo\"\n",
    "\n",
    "cluster = CHTCCluster(worker_image = WORKER_IMAGE, gpus = True)\n",
    "cluster.scale(2)\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We'll use PyTorch, a popular Python machine learning framework. PyTorch can can tell use whether it can has access to GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def probe():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    return (socket.gethostname(), device)\n",
    "\n",
    "probe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`Client.run` executes a function on each worker and send us back the results. This is not `Client.map`! `Client.run` is mainly used for diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prove we can actually do some GPU math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_addition():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    a = torch.tensor([1., 2.], device = device)\n",
    "    \n",
    "    a = a.add(1.0)\n",
    "    \n",
    "    a = a.cpu()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.delayed(tensor_addition)().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training a PyTorch model on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And now, for the grand finale, we'll perform hyperparameter optimization on a PyTorch model using our GPUs. We'll need to use the wrapper library Skorch, which overlays PyTorch with the scikit-learn API that Dask-ML expects to use. Then we just just feed the Skorch model specification to Dask-ML and it takes over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02, 0.03],\n",
    "    'max_epochs': [10, 20, 20],\n",
    "    'module__num_units': [10, 20, 30],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02, 0.03],\n",
    "    'max_epochs': [10, 20, 20],\n",
    "    'module__num_units': [10, 20, 30],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}